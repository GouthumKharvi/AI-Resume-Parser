{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88aedd7b-d41e-4d6d-a974-0d6d7b192774",
   "metadata": {},
   "source": [
    "# RESUME PARSER "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be6e601-fe2b-4ec0-85f9-58605c435f05",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project implements an AI-driven system to recommend jobs to candidates based on semantic similarity between resumes and job descriptions. It leverages pre-trained sentence transformer models to generate embeddings for job descriptions and resumes, enabling more meaningful and context-aware matching beyond simple keyword searches.\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "Traditional recruitment processes rely heavily on manual resume screening and keyword matching, which are time-consuming, inefficient, and prone to overlooking well-qualified candidates due to differences in phrasing or terminology. This results in longer hiring cycles and potentially biased selections.\n",
    "\n",
    "## Value Proposition\n",
    "\n",
    "This project demonstrates how embedding-based similarity matching can:\n",
    "\n",
    "* **Enhance Candidate-Job Fit:** By understanding the semantic content of resumes and job postings, the system provides relevant job recommendations to candidates.\n",
    "* **Increase Recruitment Efficiency:** Automating the matching process reduces manual effort and accelerates candidate shortlisting.\n",
    "* **Support Data-Driven Hiring Decisions:** Enables recruiters to prioritize candidates based on meaningful content similarity scores.\n",
    "\n",
    "## Scope\n",
    "\n",
    "* Use of the Sentence-Transformers `all-MiniLM-L6-v2` embedding model for feature extraction.\n",
    "* Processing and embedding of real-world datasets of job postings and candidate resumes.\n",
    "* Development of a recommendation mechanism that ranks top job matches for candidates based on cosine similarity.\n",
    "* Visualization of job and resume data insights using multiple plot types (bar charts, pie charts, word clouds).\n",
    "* Implementation of evaluation metrics suited for recommendation tasks (Top-K Accuracy, Precision, Recall, MRR).\n",
    "* Threshold tuning and binary classification evaluation (Precision, Recall, F1, ROC-AUC) to measure match quality.\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "* **Job Postings Dataset:** Real job descriptions with titles, companies, locations, and domains.\n",
    "* **Resume Dataset:** Candidate resumes with extracted text and metadata fields.\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "* Handling missing values in critical columns to maintain dataset quality.\n",
    "* Text normalization including lowercasing and removal of non-alphanumeric characters for consistent embedding generation.\n",
    "* Extraction of key textual features (e.g., job descriptions, resume text) to generate meaningful embeddings.\n",
    "\n",
    "## Model and Matching\n",
    "\n",
    "* Use of a sentence transformer model to convert textual data into dense vector representations.\n",
    "* Calculation of cosine similarity between job and resume embeddings to identify the best matches.\n",
    "* Application of filters and ranking to refine recommendations.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "* Use of recommendation system metrics like Top-5 Accuracy, Precision\\@5, Recall\\@5, and Mean Reciprocal Rank to evaluate ranking performance.\n",
    "* Additional binary classification metrics after threshold tuning to assess the quality of match predictions.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686da73-6d7a-49bd-b0e6-0050fd15e683",
   "metadata": {},
   "source": [
    "### Import Libraries and Install Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f359fa9d-676b-4c5c-975b-d2439cbe1e39",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: click in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.6.15)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-2.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'C:\\Users\\Gouthum\\.conda\\envs\\myenv\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.45.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.14.1 which is incompatible.\n",
      "torchvision 0.22.1 requires torch==2.7.1, but you have torch 2.1.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31ccbc35-0566-45a9-892a-139eaa40dd07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (4.30.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (0.34.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: click in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from nltk->sentence-transformers) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from nltk->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2025.6.15)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torchvision->sentence-transformers) (11.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74c5db5-c21f-4938-94fc-53cb0ba6fe94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eeb808f9-25a1-4c87-b131-3c20c789139f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (5.0.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.54.1)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (0.34.3)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing  the sentence-transformers library required for Sentence-BERT embeddings\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e9ef10-48ee-467f-8ed9-53287566c4fa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (3.8.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\gouthum\\appdata\\roaming\\python\\python312\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "714e1f0b-941a-444e-ab60-6eae783ccf17",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\compat.py\", line 99, in <module>\n",
      "    import h5py\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py\", line 45, in <module>\n",
      "    from ._conv import register_converters as _register_converters, \\\n",
      "  File \"h5py\\\\_conv.pyx\", line 1, in init h5py._conv\n",
      "  File \"h5py\\\\h5r.pyx\", line 1, in init h5py.h5r\n",
      "  File \"h5py\\\\h5p.pyx\", line 1, in init h5py.h5p\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0559e9a-3bb6-4bdd-bee9-e2c7e8d2e1df",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: keras in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (2.13.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Collecting numpy<=1.24.3,>=1.22 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached numpy-1.24.3-cp310-cp310-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.1.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.73.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.32.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2025.6.15)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipywidgets) (8.23.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (4.54.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (0.34.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Using cached numpy-1.24.3-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: typing-extensions, numpy\n",
      "\n",
      "  Attempting uninstall: typing-extensions\n",
      "\n",
      "    Found existing installation: typing_extensions 4.14.1\n",
      "\n",
      "    Uninstalling typing_extensions-4.14.1:\n",
      "\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.14.1\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "  Attempting uninstall: numpy\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "    Found existing installation: numpy 2.2.6\n",
      "   ---------------------------------------- 0/2 [typing-extensions]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "    Uninstalling numpy-2.2.6:\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   -------------------- ------------------- 1/2 [numpy]\n",
      "   ---------------------------------------- 2/2 [numpy]\n",
      "\n",
      "Successfully installed numpy-1.24.3 typing-extensions-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\Gouthum\\.conda\\envs\\myenv\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
      "optree 0.16.0 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic 2.11.7 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.33.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "streamlit 1.45.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
      "torchaudio 2.7.1 requires torch==2.7.1, but you have torch 2.1.2 which is incompatible.\n",
      "torchvision 0.22.1 requires torch==2.7.1, but you have torch 2.1.2 which is incompatible.\n",
      "typing-inspection 0.4.1 requires typing-extensions>=4.12.0, but you have typing-extensions 4.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras ipywidgets sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6637136-4818-4e2e-801c-be4e91fbc0a2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: console dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook qtconsole run script server\n",
      "troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf1bd8b-e828-4826-a34f-d60472f5ebe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9ed1dc31424c3aabb178318682a65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "widgets.IntSlider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50d5d23-3b82-44d7-8340-628b0f430df2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: console dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook qtconsole run script server\n",
      "troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd923c40-d9f1-4097-b6ed-3bcd8f71e696",
   "metadata": {},
   "source": [
    "### Imorting necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b89b531-b3b9-46f2-a34d-283cec7910c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.54.1\n",
      "Uninstalling transformers-4.54.1:\n",
      "  Successfully uninstalled transformers-4.54.1\n",
      "Found existing installation: sentence-transformers 5.0.0\n",
      "Uninstalling sentence-transformers-5.0.0:\n",
      "  Successfully uninstalled sentence-transformers-5.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall transformers sentence-transformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "095afcac-af0b-48ac-9403-f743bef23633",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.30.2\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n",
      "Collecting sentence-transformers==2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.30.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.30.2) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.30.2) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.30.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.30.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.30.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.30.2) (2.32.4)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.2)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.30.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.30.2) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (2.1.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (0.22.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (1.15.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Collecting sentencepiece (from sentence-transformers==2.2.2)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tqdm>=4.27->transformers==4.30.2) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
      "Requirement already satisfied: click in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (1.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers==4.30.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers==4.30.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers==4.30.2) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers==4.30.2) (2025.6.15)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers==2.2.2)\n",
      "  Using cached torch-2.7.1-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torchvision->sentence-transformers==2.2.2) (11.2.1)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "   ---------------------------------------- 0.0/7.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.6/7.2 MB 12.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.8/7.2 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.2/7.2 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 2.6/3.5 MB 21.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 991.5/991.5 kB 9.4 MB/s eta 0:00:00\n",
      "Using cached torch-2.7.1-cp310-cp310-win_amd64.whl (216.1 MB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=126076 sha256=3f19a86bee4b1841743e5198a5b0bc4caca811da19a0d75aab1b4e8d9e3546ab\n",
      "  Stored in directory: c:\\users\\gouthum\\appdata\\local\\pip\\cache\\wheels\\62\\f2\\10\\1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, typing-extensions, torch, transformers, sentence-transformers\n",
      "\n",
      "  Attempting uninstall: tokenizers\n",
      "\n",
      "    Found existing installation: tokenizers 0.21.4\n",
      "\n",
      "    Uninstalling tokenizers-0.21.4:\n",
      "\n",
      "      Successfully uninstalled tokenizers-0.21.4\n",
      "\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ---------------------------------------- 0/6 [tokenizers]\n",
      "   ------ --------------------------------- 1/6 [sentencepiece]\n",
      "  Attempting uninstall: typing-extensions\n",
      "   ------ --------------------------------- 1/6 [sentencepiece]\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "   ------ --------------------------------- 1/6 [sentencepiece]\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "   ------ --------------------------------- 1/6 [sentencepiece]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "  Attempting uninstall: torch\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "    Found existing installation: torch 2.1.2\n",
      "   ------------- -------------------------- 2/6 [typing-extensions]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "    Uninstalling torch-2.1.2:\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "      Successfully uninstalled torch-2.1.2\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------- ------------------- 3/6 [torch]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   -------------------------- ------------- 4/6 [transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   ---------------------------------------- 6/6 [sentence-transformers]\n",
      "\n",
      "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.2.0 tokenizers-0.13.3 torch-2.7.1 transformers-4.30.2 typing-extensions-4.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'sentence-transformers' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sentence-transformers'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Gouthum\\.conda\\envs\\myenv\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\Gouthum\\.conda\\envs\\myenv\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Gouthum\\.conda\\envs\\myenv\\Lib\\site-packages\\~-rch'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\Gouthum\\.conda\\envs\\myenv\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.45.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.14.1 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.30.2 sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7ceb625-ff9e-4160-ac11-70882e94349a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers==2.2.2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (2.2.2)\n",
      "Collecting huggingface_hub==0.10.1\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: transformers==4.30.2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (4.30.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (0.22.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (1.15.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.30.2) (3.18.0)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sentence-transformers==2.2.2\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "\n",
      "The conflict is caused by:\n",
      "    The user requested huggingface_hub==0.10.1\n",
      "    sentence-transformers 2.2.2 depends on huggingface-hub>=0.4.0\n",
      "    transformers 4.30.2 depends on huggingface-hub<1.0 and >=0.14.1\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install huggingface_hub==0.10.1, sentence-transformers==2.2.2 and transformers==4.30.2 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers==2.2.2 huggingface_hub==0.10.1 transformers==4.30.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b35c72b-a337-496e-8155-6ce9571305f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface-hub==0.14.1\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub==0.14.1) (3.18.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub==0.14.1) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub==0.14.1) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub==0.14.1) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub==0.14.1) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub==0.14.1) (4.14.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub==0.14.1) (25.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub==0.14.1) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->huggingface-hub==0.14.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->huggingface-hub==0.14.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->huggingface-hub==0.14.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->huggingface-hub==0.14.1) (2025.6.15)\n",
      "Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.34.3\n",
      "    Uninstalling huggingface-hub-0.34.3:\n",
      "      Successfully uninstalled huggingface-hub-0.34.3\n",
      "Successfully installed huggingface-hub-0.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\Gouthum\\.conda\\envs\\myenv\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.14.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface-hub==0.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cfc8ba9-2d23-4545-9b36-d1c1d832d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e2e59-8a15-4ebf-b5d5-1616ddba5f37",
   "metadata": {},
   "source": [
    "### Load Resume and Job Posting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22134313-57b3-45e8-ae73-b11eb6d8603a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumes: (2484, 4)\n",
      "Job Postings: (123849, 31)\n",
      "         ID                                         Resume_str  \\\n",
      "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
      "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
      "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
      "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
      "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
      "\n",
      "                                         Resume_html Category  \n",
      "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "4  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "     job_id            company_name  \\\n",
      "0    921716   Corcoran Sawyer Smith   \n",
      "1   1829192                     NaN   \n",
      "2  10998357  The National Exemplar    \n",
      "3  23221523  Abrams Fensterman, LLP   \n",
      "4  35982263                     NaN   \n",
      "\n",
      "                                               title  \\\n",
      "0                              Marketing Coordinator   \n",
      "1                  Mental Health Therapist/Counselor   \n",
      "2                        Assitant Restaurant Manager   \n",
      "3  Senior Elder Law / Trusts and Estates Associat...   \n",
      "4                                 Service Technician   \n",
      "\n",
      "                                         description  max_salary pay_period  \\\n",
      "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
      "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
      "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
      "3  Senior Associate Attorney - Elder Law / Trusts...    175000.0     YEARLY   \n",
      "4  Looking for HVAC service tech with experience ...     80000.0     YEARLY   \n",
      "\n",
      "            location  company_id  views  med_salary  ...  \\\n",
      "0      Princeton, NJ   2774458.0   20.0         NaN  ...   \n",
      "1   Fort Collins, CO         NaN    1.0         NaN  ...   \n",
      "2     Cincinnati, OH  64896719.0    8.0         NaN  ...   \n",
      "3  New Hyde Park, NY    766262.0   16.0         NaN  ...   \n",
      "4     Burlington, IA         NaN    3.0         NaN  ...   \n",
      "\n",
      "                                         skills_desc   listed_time  \\\n",
      "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
      "1                                                NaN  1.712858e+12   \n",
      "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
      "3  This position requires a baseline understandin...  1.712896e+12   \n",
      "4                                                NaN  1.713452e+12   \n",
      "\n",
      "   posting_domain  sponsored  work_type currency compensation_type  \\\n",
      "0             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "1             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "2             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "3             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "4             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
      "\n",
      "  normalized_salary  zip_code     fips  \n",
      "0           38480.0    8540.0  34021.0  \n",
      "1           83200.0   80521.0   8069.0  \n",
      "2           55000.0   45202.0  39061.0  \n",
      "3          157500.0   11040.0  36059.0  \n",
      "4           70000.0   52601.0  19057.0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load resumes dataset\n",
    "resumes_df = pd.read_csv(r'C:\\Users\\Gouthum\\Downloads\\PinnacleAiInternship\\Dataset\\Resume\\Resume.csv')\n",
    "\n",
    "# Load job postings dataset\n",
    "jobs_df = pd.read_csv(r'C:\\Users\\Gouthum\\Downloads\\PinnacleAiInternship\\jobdetails\\postings.csv')\n",
    "\n",
    "print(f\"Resumes: {resumes_df.shape}\")\n",
    "print(f\"Job Postings: {jobs_df.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(resumes_df.head())\n",
    "print(jobs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf5689d-8c0f-4516-8723-505a0cdfce79",
   "metadata": {},
   "source": [
    "### Resume.CSV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93082a67-6f2b-4807-abe0-0e3a55113023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>99416532</td>\n",
       "      <td>RANK: SGT/E-5 NON- COMMISSIONED OFFIC...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>AVIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>24589765</td>\n",
       "      <td>GOVERNMENT RELATIONS, COMMUNICATIONS ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>AVIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>31605080</td>\n",
       "      <td>GEEK SQUAD AGENT         Professional...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>AVIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>21190805</td>\n",
       "      <td>PROGRAM DIRECTOR / OFFICE MANAGER    ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>AVIATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>37473139</td>\n",
       "      <td>STOREKEEPER II       Professional Sum...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>AVIATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2484 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                         Resume_str  \\\n",
       "0     16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1     22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2     33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3     27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4     17812897           HR MANAGER         Skill Highlights  ...   \n",
       "...        ...                                                ...   \n",
       "2479  99416532           RANK: SGT/E-5 NON- COMMISSIONED OFFIC...   \n",
       "2480  24589765           GOVERNMENT RELATIONS, COMMUNICATIONS ...   \n",
       "2481  31605080           GEEK SQUAD AGENT         Professional...   \n",
       "2482  21190805           PROGRAM DIRECTOR / OFFICE MANAGER    ...   \n",
       "2483  37473139           STOREKEEPER II       Professional Sum...   \n",
       "\n",
       "                                            Resume_html  Category  \n",
       "0     <div class=\"fontsize fontface vmargins hmargin...        HR  \n",
       "1     <div class=\"fontsize fontface vmargins hmargin...        HR  \n",
       "2     <div class=\"fontsize fontface vmargins hmargin...        HR  \n",
       "3     <div class=\"fontsize fontface vmargins hmargin...        HR  \n",
       "4     <div class=\"fontsize fontface vmargins hmargin...        HR  \n",
       "...                                                 ...       ...  \n",
       "2479  <div class=\"fontsize fontface vmargins hmargin...  AVIATION  \n",
       "2480  <div class=\"fontsize fontface vmargins hmargin...  AVIATION  \n",
       "2481  <div class=\"fontsize fontface vmargins hmargin...  AVIATION  \n",
       "2482  <div class=\"fontsize fontface vmargins hmargin...  AVIATION  \n",
       "2483  <div class=\"fontsize fontface vmargins hmargin...  AVIATION  \n",
       "\n",
       "[2484 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a900c0a-1e76-4cd8-a409-a35f7eb36525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
       "\n",
       "                                         Resume_html Category  \n",
       "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "4  <div class=\"fontsize fontface vmargins hmargin...       HR  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4e994-d39f-44a3-baba-eec01c9c9c33",
   "metadata": {},
   "source": [
    "### postings.CSV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdabbb73-11aa-447e-a244-8b332f062055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>pay_period</th>\n",
       "      <th>location</th>\n",
       "      <th>company_id</th>\n",
       "      <th>views</th>\n",
       "      <th>med_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>skills_desc</th>\n",
       "      <th>listed_time</th>\n",
       "      <th>posting_domain</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>work_type</th>\n",
       "      <th>currency</th>\n",
       "      <th>compensation_type</th>\n",
       "      <th>normalized_salary</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Requirements: \\n\\nWe are seeking a College or ...</td>\n",
       "      <td>1.713398e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>38480.0</td>\n",
       "      <td>8540.0</td>\n",
       "      <td>34021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1829192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Fort Collins, CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.712858e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>80521.0</td>\n",
       "      <td>8069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>We are currently accepting resumes for FOH - A...</td>\n",
       "      <td>1.713278e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>45202.0</td>\n",
       "      <td>39061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23221523</td>\n",
       "      <td>Abrams Fensterman, LLP</td>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>Senior Associate Attorney - Elder Law / Trusts...</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>New Hyde Park, NY</td>\n",
       "      <td>766262.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>This position requires a baseline understandin...</td>\n",
       "      <td>1.712896e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>11040.0</td>\n",
       "      <td>36059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35982263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service Technician</td>\n",
       "      <td>Looking for HVAC service tech with experience ...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Burlington, IA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.713452e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>52601.0</td>\n",
       "      <td>19057.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123844</th>\n",
       "      <td>3906267117</td>\n",
       "      <td>Lozano Smith</td>\n",
       "      <td>Title IX/Investigations Attorney</td>\n",
       "      <td>Our Walnut Creek office is currently seeking a...</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Walnut Creek, CA</td>\n",
       "      <td>56120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.713571e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>94595.0</td>\n",
       "      <td>6013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123845</th>\n",
       "      <td>3906267126</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Staff Software Engineer, ML Serving Platform</td>\n",
       "      <td>About Pinterest:\\n\\nMillions of people across ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>1124131.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.713572e+12</td>\n",
       "      <td>www.pinterestcareers.com</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123846</th>\n",
       "      <td>3906267131</td>\n",
       "      <td>EPS Learning</td>\n",
       "      <td>Account Executive, Oregon/Washington</td>\n",
       "      <td>Company Overview\\n\\nEPS Learning is a leading ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spokane, WA</td>\n",
       "      <td>90552133.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.713572e+12</td>\n",
       "      <td>epsoperations.bamboohr.com</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99201.0</td>\n",
       "      <td>53063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123847</th>\n",
       "      <td>3906267195</td>\n",
       "      <td>Trelleborg Applied Technologies</td>\n",
       "      <td>Business Development Manager</td>\n",
       "      <td>The Business Development Manager is a 'hunter'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2793699.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.713573e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123848</th>\n",
       "      <td>3906267224</td>\n",
       "      <td>Solugenix</td>\n",
       "      <td>Marketing Social Media Specialist</td>\n",
       "      <td>Marketing Social Media Specialist - $70k – $75...</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>San Juan Capistrano, CA</td>\n",
       "      <td>43325.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.713573e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>72500.0</td>\n",
       "      <td>92675.0</td>\n",
       "      <td>6059.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123849 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            job_id                     company_name  \\\n",
       "0           921716            Corcoran Sawyer Smith   \n",
       "1          1829192                              NaN   \n",
       "2         10998357           The National Exemplar    \n",
       "3         23221523           Abrams Fensterman, LLP   \n",
       "4         35982263                              NaN   \n",
       "...            ...                              ...   \n",
       "123844  3906267117                     Lozano Smith   \n",
       "123845  3906267126                        Pinterest   \n",
       "123846  3906267131                     EPS Learning   \n",
       "123847  3906267195  Trelleborg Applied Technologies   \n",
       "123848  3906267224                        Solugenix   \n",
       "\n",
       "                                                    title  \\\n",
       "0                                   Marketing Coordinator   \n",
       "1                       Mental Health Therapist/Counselor   \n",
       "2                             Assitant Restaurant Manager   \n",
       "3       Senior Elder Law / Trusts and Estates Associat...   \n",
       "4                                      Service Technician   \n",
       "...                                                   ...   \n",
       "123844                   Title IX/Investigations Attorney   \n",
       "123845       Staff Software Engineer, ML Serving Platform   \n",
       "123846               Account Executive, Oregon/Washington   \n",
       "123847                       Business Development Manager   \n",
       "123848                  Marketing Social Media Specialist   \n",
       "\n",
       "                                              description  max_salary  \\\n",
       "0       Job descriptionA leading real estate firm in N...        20.0   \n",
       "1       At Aspen Therapy and Wellness , we are committ...        50.0   \n",
       "2       The National Exemplar is accepting application...     65000.0   \n",
       "3       Senior Associate Attorney - Elder Law / Trusts...    175000.0   \n",
       "4       Looking for HVAC service tech with experience ...     80000.0   \n",
       "...                                                   ...         ...   \n",
       "123844  Our Walnut Creek office is currently seeking a...    195000.0   \n",
       "123845  About Pinterest:\\n\\nMillions of people across ...         NaN   \n",
       "123846  Company Overview\\n\\nEPS Learning is a leading ...         NaN   \n",
       "123847  The Business Development Manager is a 'hunter'...         NaN   \n",
       "123848  Marketing Social Media Specialist - $70k – $75...     75000.0   \n",
       "\n",
       "       pay_period                 location  company_id  views  med_salary  \\\n",
       "0          HOURLY            Princeton, NJ   2774458.0   20.0         NaN   \n",
       "1          HOURLY         Fort Collins, CO         NaN    1.0         NaN   \n",
       "2          YEARLY           Cincinnati, OH  64896719.0    8.0         NaN   \n",
       "3          YEARLY        New Hyde Park, NY    766262.0   16.0         NaN   \n",
       "4          YEARLY           Burlington, IA         NaN    3.0         NaN   \n",
       "...           ...                      ...         ...    ...         ...   \n",
       "123844     YEARLY         Walnut Creek, CA     56120.0    1.0         NaN   \n",
       "123845        NaN            United States   1124131.0    3.0         NaN   \n",
       "123846        NaN              Spokane, WA  90552133.0    3.0         NaN   \n",
       "123847        NaN     Texas, United States   2793699.0    4.0         NaN   \n",
       "123848     YEARLY  San Juan Capistrano, CA     43325.0    2.0         NaN   \n",
       "\n",
       "        ...                                        skills_desc   listed_time  \\\n",
       "0       ...  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
       "1       ...                                                NaN  1.712858e+12   \n",
       "2       ...  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
       "3       ...  This position requires a baseline understandin...  1.712896e+12   \n",
       "4       ...                                                NaN  1.713452e+12   \n",
       "...     ...                                                ...           ...   \n",
       "123844  ...                                                NaN  1.713571e+12   \n",
       "123845  ...                                                NaN  1.713572e+12   \n",
       "123846  ...                                                NaN  1.713572e+12   \n",
       "123847  ...                                                NaN  1.713573e+12   \n",
       "123848  ...                                                NaN  1.713573e+12   \n",
       "\n",
       "                    posting_domain  sponsored  work_type currency  \\\n",
       "0                              NaN          0  FULL_TIME      USD   \n",
       "1                              NaN          0  FULL_TIME      USD   \n",
       "2                              NaN          0  FULL_TIME      USD   \n",
       "3                              NaN          0  FULL_TIME      USD   \n",
       "4                              NaN          0  FULL_TIME      USD   \n",
       "...                            ...        ...        ...      ...   \n",
       "123844                         NaN          0  FULL_TIME      USD   \n",
       "123845    www.pinterestcareers.com          0  FULL_TIME      NaN   \n",
       "123846  epsoperations.bamboohr.com          0  FULL_TIME      NaN   \n",
       "123847                         NaN          0  FULL_TIME      NaN   \n",
       "123848                         NaN          0  FULL_TIME      USD   \n",
       "\n",
       "       compensation_type normalized_salary  zip_code     fips  \n",
       "0            BASE_SALARY           38480.0    8540.0  34021.0  \n",
       "1            BASE_SALARY           83200.0   80521.0   8069.0  \n",
       "2            BASE_SALARY           55000.0   45202.0  39061.0  \n",
       "3            BASE_SALARY          157500.0   11040.0  36059.0  \n",
       "4            BASE_SALARY           70000.0   52601.0  19057.0  \n",
       "...                  ...               ...       ...      ...  \n",
       "123844       BASE_SALARY          157500.0   94595.0   6013.0  \n",
       "123845               NaN               NaN       NaN      NaN  \n",
       "123846               NaN               NaN   99201.0  53063.0  \n",
       "123847               NaN               NaN       NaN      NaN  \n",
       "123848       BASE_SALARY           72500.0   92675.0   6059.0  \n",
       "\n",
       "[123849 rows x 31 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b3ae585-5404-4b79-90ad-bc10fe015b18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>pay_period</th>\n",
       "      <th>location</th>\n",
       "      <th>company_id</th>\n",
       "      <th>views</th>\n",
       "      <th>med_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>skills_desc</th>\n",
       "      <th>listed_time</th>\n",
       "      <th>posting_domain</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>work_type</th>\n",
       "      <th>currency</th>\n",
       "      <th>compensation_type</th>\n",
       "      <th>normalized_salary</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Requirements: \\n\\nWe are seeking a College or ...</td>\n",
       "      <td>1.713398e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>38480.0</td>\n",
       "      <td>8540.0</td>\n",
       "      <td>34021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1829192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Fort Collins, CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.712858e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>80521.0</td>\n",
       "      <td>8069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>We are currently accepting resumes for FOH - A...</td>\n",
       "      <td>1.713278e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>45202.0</td>\n",
       "      <td>39061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23221523</td>\n",
       "      <td>Abrams Fensterman, LLP</td>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>Senior Associate Attorney - Elder Law / Trusts...</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>New Hyde Park, NY</td>\n",
       "      <td>766262.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>This position requires a baseline understandin...</td>\n",
       "      <td>1.712896e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>11040.0</td>\n",
       "      <td>36059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35982263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service Technician</td>\n",
       "      <td>Looking for HVAC service tech with experience ...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Burlington, IA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.713452e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>52601.0</td>\n",
       "      <td>19057.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id            company_name  \\\n",
       "0    921716   Corcoran Sawyer Smith   \n",
       "1   1829192                     NaN   \n",
       "2  10998357  The National Exemplar    \n",
       "3  23221523  Abrams Fensterman, LLP   \n",
       "4  35982263                     NaN   \n",
       "\n",
       "                                               title  \\\n",
       "0                              Marketing Coordinator   \n",
       "1                  Mental Health Therapist/Counselor   \n",
       "2                        Assitant Restaurant Manager   \n",
       "3  Senior Elder Law / Trusts and Estates Associat...   \n",
       "4                                 Service Technician   \n",
       "\n",
       "                                         description  max_salary pay_period  \\\n",
       "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
       "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
       "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
       "3  Senior Associate Attorney - Elder Law / Trusts...    175000.0     YEARLY   \n",
       "4  Looking for HVAC service tech with experience ...     80000.0     YEARLY   \n",
       "\n",
       "            location  company_id  views  med_salary  ...  \\\n",
       "0      Princeton, NJ   2774458.0   20.0         NaN  ...   \n",
       "1   Fort Collins, CO         NaN    1.0         NaN  ...   \n",
       "2     Cincinnati, OH  64896719.0    8.0         NaN  ...   \n",
       "3  New Hyde Park, NY    766262.0   16.0         NaN  ...   \n",
       "4     Burlington, IA         NaN    3.0         NaN  ...   \n",
       "\n",
       "                                         skills_desc   listed_time  \\\n",
       "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
       "1                                                NaN  1.712858e+12   \n",
       "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
       "3  This position requires a baseline understandin...  1.712896e+12   \n",
       "4                                                NaN  1.713452e+12   \n",
       "\n",
       "   posting_domain  sponsored  work_type currency compensation_type  \\\n",
       "0             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "1             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "2             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "3             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "4             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "\n",
       "  normalized_salary  zip_code     fips  \n",
       "0           38480.0    8540.0  34021.0  \n",
       "1           83200.0   80521.0   8069.0  \n",
       "2           55000.0   45202.0  39061.0  \n",
       "3          157500.0   11040.0  36059.0  \n",
       "4           70000.0   52601.0  19057.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d6d3d00-32c0-4ed5-92b8-5a07a57eaa85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>pay_period</th>\n",
       "      <th>location</th>\n",
       "      <th>company_id</th>\n",
       "      <th>views</th>\n",
       "      <th>med_salary</th>\n",
       "      <th>...</th>\n",
       "      <th>skills_desc</th>\n",
       "      <th>listed_time</th>\n",
       "      <th>posting_domain</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>work_type</th>\n",
       "      <th>currency</th>\n",
       "      <th>compensation_type</th>\n",
       "      <th>normalized_salary</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>Corcoran Sawyer Smith</td>\n",
       "      <td>Marketing Coordinator</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Princeton, NJ</td>\n",
       "      <td>2774458.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Requirements: \\n\\nWe are seeking a College or ...</td>\n",
       "      <td>1.713398e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>38480.0</td>\n",
       "      <td>8540.0</td>\n",
       "      <td>34021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1829192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mental Health Therapist/Counselor</td>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Fort Collins, CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.712858e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>83200.0</td>\n",
       "      <td>80521.0</td>\n",
       "      <td>8069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10998357</td>\n",
       "      <td>The National Exemplar</td>\n",
       "      <td>Assitant Restaurant Manager</td>\n",
       "      <td>The National Exemplar is accepting application...</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>64896719.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>We are currently accepting resumes for FOH - A...</td>\n",
       "      <td>1.713278e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>45202.0</td>\n",
       "      <td>39061.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23221523</td>\n",
       "      <td>Abrams Fensterman, LLP</td>\n",
       "      <td>Senior Elder Law / Trusts and Estates Associat...</td>\n",
       "      <td>Senior Associate Attorney - Elder Law / Trusts...</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>New Hyde Park, NY</td>\n",
       "      <td>766262.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>This position requires a baseline understandin...</td>\n",
       "      <td>1.712896e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>11040.0</td>\n",
       "      <td>36059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35982263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service Technician</td>\n",
       "      <td>Looking for HVAC service tech with experience ...</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Burlington, IA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.713452e+12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>FULL_TIME</td>\n",
       "      <td>USD</td>\n",
       "      <td>BASE_SALARY</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>52601.0</td>\n",
       "      <td>19057.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id            company_name  \\\n",
       "0    921716   Corcoran Sawyer Smith   \n",
       "1   1829192                     NaN   \n",
       "2  10998357  The National Exemplar    \n",
       "3  23221523  Abrams Fensterman, LLP   \n",
       "4  35982263                     NaN   \n",
       "\n",
       "                                               title  \\\n",
       "0                              Marketing Coordinator   \n",
       "1                  Mental Health Therapist/Counselor   \n",
       "2                        Assitant Restaurant Manager   \n",
       "3  Senior Elder Law / Trusts and Estates Associat...   \n",
       "4                                 Service Technician   \n",
       "\n",
       "                                         description  max_salary pay_period  \\\n",
       "0  Job descriptionA leading real estate firm in N...        20.0     HOURLY   \n",
       "1  At Aspen Therapy and Wellness , we are committ...        50.0     HOURLY   \n",
       "2  The National Exemplar is accepting application...     65000.0     YEARLY   \n",
       "3  Senior Associate Attorney - Elder Law / Trusts...    175000.0     YEARLY   \n",
       "4  Looking for HVAC service tech with experience ...     80000.0     YEARLY   \n",
       "\n",
       "            location  company_id  views  med_salary  ...  \\\n",
       "0      Princeton, NJ   2774458.0   20.0         NaN  ...   \n",
       "1   Fort Collins, CO         NaN    1.0         NaN  ...   \n",
       "2     Cincinnati, OH  64896719.0    8.0         NaN  ...   \n",
       "3  New Hyde Park, NY    766262.0   16.0         NaN  ...   \n",
       "4     Burlington, IA         NaN    3.0         NaN  ...   \n",
       "\n",
       "                                         skills_desc   listed_time  \\\n",
       "0  Requirements: \\n\\nWe are seeking a College or ...  1.713398e+12   \n",
       "1                                                NaN  1.712858e+12   \n",
       "2  We are currently accepting resumes for FOH - A...  1.713278e+12   \n",
       "3  This position requires a baseline understandin...  1.712896e+12   \n",
       "4                                                NaN  1.713452e+12   \n",
       "\n",
       "   posting_domain  sponsored  work_type currency compensation_type  \\\n",
       "0             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "1             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "2             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "3             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "4             NaN          0  FULL_TIME      USD       BASE_SALARY   \n",
       "\n",
       "  normalized_salary  zip_code     fips  \n",
       "0           38480.0    8540.0  34021.0  \n",
       "1           83200.0   80521.0   8069.0  \n",
       "2           55000.0   45202.0  39061.0  \n",
       "3          157500.0   11040.0  36059.0  \n",
       "4           70000.0   52601.0  19057.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings_path = r\"C:\\Users\\Gouthum\\Downloads\\PinnacleAiInternship\\jobdetails\\postings.csv\"\n",
    "\n",
    "# Load the Job Postings CSV file into a Pandas DataFrame\n",
    "postings_df = pd.read_csv(postings_path)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "postings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c13275a-32fe-4eec-a2ff-3710ad043765",
   "metadata": {},
   "source": [
    "### Size of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a8dfd12-bf46-4c2e-96fb-579a039de37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumes: (2484, 4)\n",
      "Job Postings: (123849, 31)\n"
     ]
    }
   ],
   "source": [
    "#Resume.CSV\n",
    "print(f\"Resumes: {resumes_df.shape}\")\n",
    "\n",
    "#postings.csv\n",
    "print(f\"Job Postings: {jobs_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61966943-547b-4223-ae97-0252b28ba037",
   "metadata": {},
   "source": [
    "### Statistics of Resume.CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8436927d-22b8-41f3-a050-8682e85c64d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.484000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.182616e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.145735e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.547447e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.754430e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.521031e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.611444e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.980612e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID\n",
       "count  2.484000e+03\n",
       "mean   3.182616e+07\n",
       "std    2.145735e+07\n",
       "min    3.547447e+06\n",
       "25%    1.754430e+07\n",
       "50%    2.521031e+07\n",
       "75%    3.611444e+07\n",
       "max    9.980612e+07"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a98a9af-5be0-4ec4-8686-495f45c7dd9e",
   "metadata": {},
   "source": [
    "### Statistics of postings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80ea4dff-440a-4c86-9500-2786c3125931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>max_salary</th>\n",
       "      <th>company_id</th>\n",
       "      <th>views</th>\n",
       "      <th>med_salary</th>\n",
       "      <th>min_salary</th>\n",
       "      <th>applies</th>\n",
       "      <th>original_listed_time</th>\n",
       "      <th>remote_allowed</th>\n",
       "      <th>expiry</th>\n",
       "      <th>closed_time</th>\n",
       "      <th>listed_time</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>normalized_salary</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>fips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.238490e+05</td>\n",
       "      <td>2.979300e+04</td>\n",
       "      <td>1.221320e+05</td>\n",
       "      <td>122160.000000</td>\n",
       "      <td>6280.000000</td>\n",
       "      <td>2.979300e+04</td>\n",
       "      <td>23320.000000</td>\n",
       "      <td>1.238490e+05</td>\n",
       "      <td>15246.0</td>\n",
       "      <td>1.238490e+05</td>\n",
       "      <td>1.073000e+03</td>\n",
       "      <td>1.238490e+05</td>\n",
       "      <td>123849.0</td>\n",
       "      <td>3.607300e+04</td>\n",
       "      <td>102977.000000</td>\n",
       "      <td>96434.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.896402e+09</td>\n",
       "      <td>9.193942e+04</td>\n",
       "      <td>1.220401e+07</td>\n",
       "      <td>14.618247</td>\n",
       "      <td>22015.619876</td>\n",
       "      <td>6.491085e+04</td>\n",
       "      <td>10.591981</td>\n",
       "      <td>1.713152e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.716213e+12</td>\n",
       "      <td>1.712928e+12</td>\n",
       "      <td>1.713204e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.053270e+05</td>\n",
       "      <td>50400.491887</td>\n",
       "      <td>28713.879887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.404355e+07</td>\n",
       "      <td>7.011101e+05</td>\n",
       "      <td>2.554143e+07</td>\n",
       "      <td>85.903598</td>\n",
       "      <td>52255.873846</td>\n",
       "      <td>4.959738e+05</td>\n",
       "      <td>29.047395</td>\n",
       "      <td>4.848209e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.321394e+09</td>\n",
       "      <td>3.622893e+08</td>\n",
       "      <td>3.989122e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.097627e+06</td>\n",
       "      <td>30252.232515</td>\n",
       "      <td>16015.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.217160e+05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.009000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.701811e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.712903e+12</td>\n",
       "      <td>1.712346e+12</td>\n",
       "      <td>1.711317e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1003.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.894587e+09</td>\n",
       "      <td>4.828000e+01</td>\n",
       "      <td>1.435200e+04</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.940000</td>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.712863e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.715481e+12</td>\n",
       "      <td>1.712670e+12</td>\n",
       "      <td>1.712886e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.200000e+04</td>\n",
       "      <td>24112.000000</td>\n",
       "      <td>13121.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.901998e+09</td>\n",
       "      <td>8.000000e+04</td>\n",
       "      <td>2.269650e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.713395e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.716042e+12</td>\n",
       "      <td>1.712670e+12</td>\n",
       "      <td>1.713408e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.150000e+04</td>\n",
       "      <td>48059.000000</td>\n",
       "      <td>29183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.904707e+09</td>\n",
       "      <td>1.400000e+05</td>\n",
       "      <td>8.047188e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2510.500000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.713478e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.716088e+12</td>\n",
       "      <td>1.713283e+12</td>\n",
       "      <td>1.713484e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250000e+05</td>\n",
       "      <td>78201.000000</td>\n",
       "      <td>42077.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.906267e+09</td>\n",
       "      <td>1.200000e+08</td>\n",
       "      <td>1.034730e+08</td>\n",
       "      <td>9975.000000</td>\n",
       "      <td>750000.000000</td>\n",
       "      <td>8.500000e+07</td>\n",
       "      <td>967.000000</td>\n",
       "      <td>1.713573e+12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.729125e+12</td>\n",
       "      <td>1.713562e+12</td>\n",
       "      <td>1.713573e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.356000e+08</td>\n",
       "      <td>99901.000000</td>\n",
       "      <td>56045.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_id    max_salary    company_id          views     med_salary  \\\n",
       "count  1.238490e+05  2.979300e+04  1.221320e+05  122160.000000    6280.000000   \n",
       "mean   3.896402e+09  9.193942e+04  1.220401e+07      14.618247   22015.619876   \n",
       "std    8.404355e+07  7.011101e+05  2.554143e+07      85.903598   52255.873846   \n",
       "min    9.217160e+05  1.000000e+00  1.009000e+03       1.000000       0.000000   \n",
       "25%    3.894587e+09  4.828000e+01  1.435200e+04       3.000000      18.940000   \n",
       "50%    3.901998e+09  8.000000e+04  2.269650e+05       4.000000      25.500000   \n",
       "75%    3.904707e+09  1.400000e+05  8.047188e+06       8.000000    2510.500000   \n",
       "max    3.906267e+09  1.200000e+08  1.034730e+08    9975.000000  750000.000000   \n",
       "\n",
       "         min_salary       applies  original_listed_time  remote_allowed  \\\n",
       "count  2.979300e+04  23320.000000          1.238490e+05         15246.0   \n",
       "mean   6.491085e+04     10.591981          1.713152e+12             1.0   \n",
       "std    4.959738e+05     29.047395          4.848209e+08             0.0   \n",
       "min    1.000000e+00      1.000000          1.701811e+12             1.0   \n",
       "25%    3.700000e+01      1.000000          1.712863e+12             1.0   \n",
       "50%    6.000000e+04      3.000000          1.713395e+12             1.0   \n",
       "75%    1.000000e+05      8.000000          1.713478e+12             1.0   \n",
       "max    8.500000e+07    967.000000          1.713573e+12             1.0   \n",
       "\n",
       "             expiry   closed_time   listed_time  sponsored  normalized_salary  \\\n",
       "count  1.238490e+05  1.073000e+03  1.238490e+05   123849.0       3.607300e+04   \n",
       "mean   1.716213e+12  1.712928e+12  1.713204e+12        0.0       2.053270e+05   \n",
       "std    2.321394e+09  3.622893e+08  3.989122e+08        0.0       5.097627e+06   \n",
       "min    1.712903e+12  1.712346e+12  1.711317e+12        0.0       0.000000e+00   \n",
       "25%    1.715481e+12  1.712670e+12  1.712886e+12        0.0       5.200000e+04   \n",
       "50%    1.716042e+12  1.712670e+12  1.713408e+12        0.0       8.150000e+04   \n",
       "75%    1.716088e+12  1.713283e+12  1.713484e+12        0.0       1.250000e+05   \n",
       "max    1.729125e+12  1.713562e+12  1.713573e+12        0.0       5.356000e+08   \n",
       "\n",
       "            zip_code          fips  \n",
       "count  102977.000000  96434.000000  \n",
       "mean    50400.491887  28713.879887  \n",
       "std     30252.232515  16015.929825  \n",
       "min      1001.000000   1003.000000  \n",
       "25%     24112.000000  13121.000000  \n",
       "50%     48059.000000  29183.000000  \n",
       "75%     78201.000000  42077.000000  \n",
       "max     99901.000000  56045.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5f0fb-b1fc-4b5e-a856-40b1c14573f5",
   "metadata": {},
   "source": [
    "# Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9777f3bb-4919-4ece-bf1e-28535434ac53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(jobs_df))\n",
    "print(type(resumes_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5172e73-df0f-41b0-af47-a17cfc79f3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs df rows: 123849\n",
      "Resumes df rows: 2484\n"
     ]
    }
   ],
   "source": [
    "print(\"Jobs df rows:\", jobs_df.shape[0])\n",
    "print(\"Resumes df rows:\", resumes_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d2ae1d9-5df5-482e-9042-9ce170954a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Postings Sample Shape: (2000, 31)\n",
      "Resume Sample Shape: (2000, 4)\n"
     ]
    }
   ],
   "source": [
    "postings_sample_df = jobs_df.sample(2000, random_state=42).copy()\n",
    "resume_sample_df = resumes_df.sample(2000, random_state=42).copy()\n",
    "\n",
    "print('Job Postings Sample Shape:', postings_sample_df.shape)\n",
    "print('Resume Sample Shape:', resume_sample_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e539af70-57f9-4a8d-9136-97b4c6245686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Sample File Sucessfully\n"
     ]
    }
   ],
   "source": [
    "postings_sample_df.to_csv(r\"C:\\Users\\Gouthum\\Downloads\\PinnacleAiInternship\\postings_sample.csv\", index=False)\n",
    "resume_sample_df.to_csv(r\"C:\\Users\\Gouthum\\Downloads\\PinnacleAiInternship\\resume_sample.csv\", index=False)\n",
    "print(\"Saved Sample File Sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "985503e2-68d7-4a76-abca-aefdca2b1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for dynamic resume and JD input\n",
    "uploaded_resume = None\n",
    "uploaded_jd = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7582ca87-c90b-45a3-9f87-d9ef090914d5",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "This stage prepares raw product text data (like product name, description, specifications) for modeling by cleaning and normalizing it.\n",
    "\n",
    "🔧 Tasks Performed:\n",
    "Handle Missing Values\n",
    "\n",
    "Dropped or filled missing values in key fields like description, product_name, and product_specifications.\n",
    "\n",
    "Text Cleaning & Normalization\n",
    "Applied preprocessing to ensure consistency and remove noise:\n",
    "\n",
    "Lowercasing all text\n",
    "\n",
    "Removing punctuation, special characters, and digits\n",
    "\n",
    "Removing extra white spaces\n",
    "\n",
    "Tokenization (breaking text into words)\n",
    "\n",
    "Stopword removal (removing words like \"and\", \"the\", etc.)\n",
    "\n",
    "Lemmatization (converting words to their base form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f144ae-f7e3-46a9-892e-dc2e27b96ba5",
   "metadata": {},
   "source": [
    "#### Preprocess and Extract Features from the Job Description Dataset¶\n",
    "This process involves:\n",
    "\n",
    "Handling missing values.\n",
    "Normalizing text fields (e.g., lemmatizing with spaCy, converting to lowercase).\n",
    "Extracting structured features (skills, domains) using predefined lists.\n",
    "Creating a single string representation of each job posting and resume, enhanced with extracted skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52996c7b-598a-4f7f-b455-ee0f14d34189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b80912a-5383-4063-b244-30240b03cb3d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Gouthum/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Gouthum/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "31f5c3b6-d58e-40b6-84c2-5509a171e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9508eb69-a7de-44f2-b53e-639a4e5fbea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1450b89d-3b1b-4585-8eab-8045f10510b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordNetLemmatizer>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85944490-62cc-45ef-bc24-55c33fe347cf",
   "metadata": {},
   "source": [
    "#### Preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c498cba-1718-4c4e-94cb-574eb4538f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original': ['looking', 'for', 'a', 'python', 'developer', 'with', 'experience', 'in', 'aws', 'and', 'docker', 'wanted', '5years', 'expereince', 'in', 'healthcare', 'finance', 'tech'], 'lemmatized': 'looking python developer experience aws docker wanted 5years expereince healthcare finance tech'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return {'original': [], 'lemmatized': ''}\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "    tokens = word_tokenize(text)\n",
    "    original_terms = tokens\n",
    "    lemmatized_terms = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    lemmatized = ' '.join(lemmatized_terms)\n",
    "    return {'original': original_terms, 'lemmatized': lemmatized}\n",
    "\n",
    "text = \"Looking for a python developer with experience in AWS and docker, wanted 5+years expereince in healthcare', 'finance', 'tech'.\"\n",
    "\n",
    "result = preprocess_text(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d6febf0-cf2c-4e9a-a0f3-b9b043feb257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Looking for a python developer with experience in AWS and docker, wanted 5+years expereince in healthcare', 'finance', 'tech'.\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "55a8589c-deaa-43ca-8d43-969f73fa70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Setup\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return {'original': [], 'lemmatized': ''}\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "    tokens = word_tokenize(text)\n",
    "    original_terms = tokens\n",
    "    lemmatized_terms = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    lemmatized = ' '.join(lemmatized_terms)\n",
    "    return {'original': original_terms, 'lemmatized': lemmatized}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1743751d-d1cd-4875-b074-78848592d708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tokens: ['looking', 'for', 'a', 'python', 'developer', 'with', 'experience', 'in', 'aws', 'and', 'docker', 'wanted', '5years', 'expereince', 'in', 'healthcare', 'finance', 'tech']\n",
      "Lemmatized: looking python developer experience aws docker wanted 5years expereince healthcare finance tech\n"
     ]
    }
   ],
   "source": [
    "text = \"Looking for a python developer with experience in AWS and docker, wanted 5+years expereince in healthcare', 'finance', 'tech'.\"\n",
    "result = preprocess_text(text)\n",
    "\n",
    "print(\"Original tokens:\", result['original'])\n",
    "print(\"Lemmatized:\", result['lemmatized'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb732476-6a4c-49ec-8d1f-94b66f6e1c18",
   "metadata": {},
   "source": [
    "### def extract_skills(text_data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8344719d-f59e-4b9d-b647-e4d1c89f25ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Skills: ['python', 'aws', 'docker']\n"
     ]
    }
   ],
   "source": [
    "# Example SKILLS list\n",
    "SKILLS = ['python', 'aws', 'docker', 'java', 'sql']\n",
    "\n",
    "# Example processed text from a resume/job description\n",
    "text_data = {\n",
    "    'original': ['looking', 'for', 'a', 'python', 'developer', 'with', 'experience', 'in', 'aws', 'and', 'docker'],\n",
    "    'lemmatized': 'looking python developer experience aws docker'\n",
    "}\n",
    "\n",
    "def extract_skills(text_data):\n",
    "    if pd.isna(text_data) or not isinstance(text_data, dict):\n",
    "        return []\n",
    "    original_terms = text_data['original']\n",
    "    return [skill for skill in SKILLS if any(skill in term for term in original_terms)]\n",
    "\n",
    "# Call the function\n",
    "extracted = extract_skills(text_data)\n",
    "print(\"Extracted Skills:\", extracted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4defec-00d4-4657-bc19-87498fd4ed16",
   "metadata": {},
   "source": [
    "### Extract Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2d45da5a-c09f-471e-af4f-28214dba2cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Domains: ['tech', 'healthcare', 'finance', 'education', 'business']\n"
     ]
    }
   ],
   "source": [
    "# Example dictionary (like one processed from resume text)\n",
    "text_data = {\n",
    "    'original': ['looking', 'for', 'python', 'developer', 'aws', 'docker', 'kubernetes', 'cloud'],\n",
    "    'lemmatized': 'looking python developer aws docker kubernetes cloud'\n",
    "}\n",
    "\n",
    "\n",
    "DOMAINS = ['tech', 'healthcare', 'finance', 'education', 'business']\n",
    "\n",
    "\n",
    "# Reuse extract_domains function\n",
    "def extract_domains(text_data, skills=None):\n",
    "    if pd.isna(text_data) or not isinstance(text_data, dict):\n",
    "        return []\n",
    "    original_terms = text_data['original']\n",
    "    domains = [domain for domain in DOMAINS if any(domain in term for term in original_terms)]\n",
    "    if skills:\n",
    "        if 'aws' in skills or 'kubernetes' in skills or 'docker' in skills:\n",
    "            domains.append('tech')\n",
    "        if 'management' in skills or 'leadership' in skills:\n",
    "            domains.append('business')\n",
    "    return list(set(domains))  # Remove duplicates\n",
    "\n",
    "\n",
    "domains = extract_domains(text_data)\n",
    "\n",
    "\n",
    "print(\"Extracted Domains:\", DOMAINS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c0aebb-2075-4183-a0bd-bf23cf56b861",
   "metadata": {},
   "source": [
    "### Apply preprocessing to job postings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e00c8285-87e9-4b25-8861-98dc728cff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "postings_sample_df['processed_desc'] = postings_sample_df['description'].apply(preprocess_text)\n",
    "postings_sample_df['job_skills'] = postings_sample_df['processed_desc'].apply(extract_skills)\n",
    "postings_sample_df['job_domain'] = postings_sample_df.apply(lambda x: extract_domains(x['processed_desc'], x['job_skills']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f9a817aa-eddc-4b58-bbb9-31fdb4d466a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73989     {'original': ['the', 'senior', 'automation', '...\n",
       "59308     {'original': ['company', 'summary', 'dish', 'a...\n",
       "44663     {'original': ['division', 'north', 'alabama', ...\n",
       "81954     {'original': ['kmgh', 'the', 'ew', 'scripps', ...\n",
       "113151    {'original': ['come', 'for', 'the', 'flexibili...\n",
       "                                ...                        \n",
       "74903     {'original': ['rd', 'staff', 'chemist', 'coati...\n",
       "11601     {'original': ['about', 'the', 'companyour', 'c...\n",
       "53215     {'original': ['medpro', 'healthcare', 'staffin...\n",
       "50579     {'original': ['overview', 'systems', 'planning...\n",
       "66711     {'original': ['overview', 'financial', 'specia...\n",
       "Name: processed_desc, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings_sample_df['processed_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "57c4f3a6-dfc2-4666-8ae0-be172d80c278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73989        []\n",
       "59308        []\n",
       "44663        []\n",
       "81954     [aws]\n",
       "113151    [aws]\n",
       "          ...  \n",
       "74903        []\n",
       "11601        []\n",
       "53215        []\n",
       "50579        []\n",
       "66711        []\n",
       "Name: job_skills, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings_sample_df['job_skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "77be62b9-6552-41ae-ba13-796178172d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73989      [business, tech]\n",
       "59308      [business, tech]\n",
       "44663     [tech, education]\n",
       "81954      [business, tech]\n",
       "113151               [tech]\n",
       "                ...        \n",
       "74903                [tech]\n",
       "11601       [tech, finance]\n",
       "53215          [healthcare]\n",
       "50579      [business, tech]\n",
       "66711                    []\n",
       "Name: job_domain, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings_sample_df['job_domain']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4e6c09-4061-4b39-818b-77871b72e28b",
   "metadata": {},
   "source": [
    "### Apply preprocessing to resumes (using Resume_str as the main text field)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0cc1e456-62c2-45d3-bc43-4b0c1391636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_sample_df['processed_resume'] = resume_sample_df['Resume_str'].apply(preprocess_text)\n",
    "resume_sample_df['cv_skills'] = resume_sample_df['processed_resume'].apply(extract_skills)\n",
    "resume_sample_df['cv_domain'] = resume_sample_df.apply(lambda x: extract_domains(x['processed_resume'], x['cv_skills']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c8dc279e-afea-4377-b3c0-a13123169807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420     {'original': ['kpandipou', 'koffi', 'summary',...\n",
       "1309    {'original': ['director', 'of', 'digital', 'tr...\n",
       "2023    {'original': ['senior', 'project', 'manager', ...\n",
       "1360    {'original': ['chef', 'summary', 'experienced'...\n",
       "2186    {'original': ['operations', 'manager', 'summar...\n",
       "                              ...                        \n",
       "750     {'original': ['claims', 'service', 'specialist...\n",
       "657     {'original': ['business', 'development', 'cons...\n",
       "1866    {'original': ['senior', 'accountant', 'summary...\n",
       "234     {'original': ['information', 'technology', 'sp...\n",
       "732     {'original': ['customer', 'service', 'represen...\n",
       "Name: processed_resume, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_sample_df['processed_resume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "81c4acc4-e691-4a5d-bbdf-552cf8b33fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420     []\n",
       "1309    []\n",
       "2023    []\n",
       "1360    []\n",
       "2186    []\n",
       "        ..\n",
       "750     []\n",
       "657     []\n",
       "1866    []\n",
       "234     []\n",
       "732     []\n",
       "Name: cv_skills, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_sample_df['cv_skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ab9c3438-40a7-4de3-83e2-a037605761c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420                 [business, education]\n",
       "1309          [business, tech, education]\n",
       "2023       [business, education, finance]\n",
       "1360                                   []\n",
       "2186          [business, tech, education]\n",
       "                      ...                \n",
       "750     [healthcare, business, education]\n",
       "657           [business, tech, education]\n",
       "1866                          [education]\n",
       "234           [business, tech, education]\n",
       "732         [healthcare, tech, education]\n",
       "Name: cv_domain, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_sample_df['cv_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5ac03bd9-fd16-4cc7-a6f8-b41c7c974da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted skills: []\n"
     ]
    }
   ],
   "source": [
    "    print(\"Extracted skills:\", resume_sample_df['cv_skills'].iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9de09942-3a6a-4c7b-b46c-05ed632b22bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume:            Kpandipou    Koffi         Summary      Compassionate teaching professional delivering exemplary support and assistance to teachers and students. Display exceptional Communication and problem solving skills.  Experience in office administration and public speaking. Attentive and adaptable, skilled in management of classroom operations. Effective in leveraging student feedback to create dynamic lesson plans that address individual strengths and weaknesses.  Dedicated and responsive team leader with proven skills in classroom management, behavior modification and individualized support.  Personable with experience using relationship-building to cultivate positive client, staff and management connections. Highly-developed communicator with outstanding skills in complex problem-solving and conflict resolution.  High-performing Administrative Assistant offering experience working with diverse client base and delivering exceptional results. Polished in managing client relations, and managing vendor relationships.  Results-driven assistant with track record of excelling in fast-paced office environments.  Career-minded with talents in preparing reports, taking messages and sorting and routing mail. Comfortable working in fast-paced, demanding office environment.  Energetic and reputable individual possessing strong work ethic, professional demeanor and superb initiative. Exceptional customer service and decision-making skills.  Service-oriented individual with expertise in preparing and modifying documents, coordinating meetings and trips and preparing responses on behalf of company. Committed to establishing stellar rapport with clients of diverse backgrounds.  Meticulous and systematic Administrative Assistant skilled in organizing, planning and managing daily clerical needs. Bringing solid expertise in coordinating documents, reports and records, handling correspondence and managing deliveries.  Skilled in oral and written communication, team leadership and relationship-building.  Comfortable working alone or with teams to accomplish on-time and accurate clerical tasks. Punctual Administrative Assistant known for having terrific work ethic and dynamic communication skills.  Adept at preparing correspondence, memoranda and reports in both draft and final form.        Skills          Superb communication both verbal and written.  Reliability and self sufficiency.  Strong work ethic.  Organizational and problem solving skills.  Team player and multi tasker.      Career minded, result driven, and goal oriented.  Adaptable, positive, eager to contribute in any capacity.  Microsoft Office  Fluent in French and English            Experience      Assistant Teacher     City  ,   State      Company Name  /   Jan 2010   to   Jun 2011       Implemented lesson plans for class of 30 students.  Prepared, duplicated and collected teaching materials to help students better understand learning concepts.  Helped students take advantage of other available subject matter and study resources.  Classroom restocking, support and management of operations.  Arranged and led activities for students, including small group and individualized instructions.  Assisted teachers with lesson preparation, curriculum implementation, and testing.          Assistant Manager Intern     City  ,   State      Company Name  /   May 2006   to   Sep 2006       Spearheaded training initiatives to improve employee performance and bottom-line business results.  Generated reports to assess performance and make adjustments.  Increased customer base and market share by promoting product through diverse channels.  Optimized productivity, streamlined program efficiency, and boosted profitability.  Supervised and trained customer service team members to provide exceptional service, driving retention and satisfaction.  Remained calm and professional in stressful circumstances and when dealing with unhappy customers, effectively diffusing situations.  Addressed internal and customer-related issues each day and affected strategic resolutions.          Junior Editor     City  ,   State      Company Name  /   Sep 2004   to   Sep 2006       Determined appropriate page budgets and layouts to guide word count parameters, optimize use of images and graphics as well as maximize impact within allotted space.  Evaluated reporter stories, shaped content and helped improve overall work quality through careful review, detailed editing and constructive feedback.  Developed and deepened positive relationships with writing, design and production team members to improve communication and collaboration.  Handed out story assignments, directed content meetings and evaluated submitted pieces to manage overall tone and execution of work.  Decided readiness of articles for publication and approved final versions.  Edited, rewrote and prepared numerous pieces per week by adjusting reading level to make understanding articles easier and more interesting.  Oversaw layout design and worked with production team members to complete fresh monthly publications          Education and Training      MBA  :   Marketing    IGlobal University     Jun 2015     City  ,   State        Major in Marketing  Completed coursework in          BBA  :   Business Administration    Golden Gate University     Jun 2011     City  ,   State        International Student Scholarship Recipient  Minor in International Business          Associate of Arts      Suffolk University     Jun 2007     City         Associate in International Business and Business Administration        \n",
      "Tokens: ['kpandipou', 'koffi', 'summary', 'compassionate', 'teaching', 'professional', 'delivering', 'exemplary', 'support', 'and', 'assistance', 'to', 'teachers', 'and', 'students', 'display', 'exceptional', 'communication', 'and', 'problem', 'solving', 'skills', 'experience', 'in', 'office', 'administration', 'and', 'public', 'speaking', 'attentive', 'and', 'adaptable', 'skilled', 'in', 'management', 'of', 'classroom', 'operations', 'effective', 'in', 'leveraging', 'student', 'feedback', 'to', 'create', 'dynamic', 'lesson', 'plans', 'that', 'address', 'individual', 'strengths', 'and', 'weaknesses', 'dedicated', 'and', 'responsive', 'team', 'leader', 'with', 'proven', 'skills', 'in', 'classroom', 'management', 'behavior', 'modification', 'and', 'individualized', 'support', 'personable', 'with', 'experience', 'using', 'relationshipbuilding', 'to', 'cultivate', 'positive', 'client', 'staff', 'and', 'management', 'connections', 'highlydeveloped', 'communicator', 'with', 'outstanding', 'skills', 'in', 'complex', 'problemsolving', 'and', 'conflict', 'resolution', 'highperforming', 'administrative', 'assistant', 'offering', 'experience', 'working', 'with', 'diverse', 'client', 'base', 'and', 'delivering', 'exceptional', 'results', 'polished', 'in', 'managing', 'client', 'relations', 'and', 'managing', 'vendor', 'relationships', 'resultsdriven', 'assistant', 'with', 'track', 'record', 'of', 'excelling', 'in', 'fastpaced', 'office', 'environments', 'careerminded', 'with', 'talents', 'in', 'preparing', 'reports', 'taking', 'messages', 'and', 'sorting', 'and', 'routing', 'mail', 'comfortable', 'working', 'in', 'fastpaced', 'demanding', 'office', 'environment', 'energetic', 'and', 'reputable', 'individual', 'possessing', 'strong', 'work', 'ethic', 'professional', 'demeanor', 'and', 'superb', 'initiative', 'exceptional', 'customer', 'service', 'and', 'decisionmaking', 'skills', 'serviceoriented', 'individual', 'with', 'expertise', 'in', 'preparing', 'and', 'modifying', 'documents', 'coordinating', 'meetings', 'and', 'trips', 'and', 'preparing', 'responses', 'on', 'behalf', 'of', 'company', 'committed', 'to', 'establishing', 'stellar', 'rapport', 'with', 'clients', 'of', 'diverse', 'backgrounds', 'meticulous', 'and', 'systematic', 'administrative', 'assistant', 'skilled', 'in', 'organizing', 'planning', 'and', 'managing', 'daily', 'clerical', 'needs', 'bringing', 'solid', 'expertise', 'in', 'coordinating', 'documents', 'reports', 'and', 'records', 'handling', 'correspondence', 'and', 'managing', 'deliveries', 'skilled', 'in', 'oral', 'and', 'written', 'communication', 'team', 'leadership', 'and', 'relationshipbuilding', 'comfortable', 'working', 'alone', 'or', 'with', 'teams', 'to', 'accomplish', 'ontime', 'and', 'accurate', 'clerical', 'tasks', 'punctual', 'administrative', 'assistant', 'known', 'for', 'having', 'terrific', 'work', 'ethic', 'and', 'dynamic', 'communication', 'skills', 'adept', 'at', 'preparing', 'correspondence', 'memoranda', 'and', 'reports', 'in', 'both', 'draft', 'and', 'final', 'form', 'skills', 'superb', 'communication', 'both', 'verbal', 'and', 'written', 'reliability', 'and', 'self', 'sufficiency', 'strong', 'work', 'ethic', 'organizational', 'and', 'problem', 'solving', 'skills', 'team', 'player', 'and', 'multi', 'tasker', 'career', 'minded', 'result', 'driven', 'and', 'goal', 'oriented', 'adaptable', 'positive', 'eager', 'to', 'contribute', 'in', 'any', 'capacity', 'microsoft', 'office', 'fluent', 'in', 'french', 'and', 'english', 'experience', 'assistant', 'teacher', 'city', 'state', 'company', 'name', 'jan', '2010', 'to', 'jun', '2011', 'implemented', 'lesson', 'plans', 'for', 'class', 'of', '30', 'students', 'prepared', 'duplicated', 'and', 'collected', 'teaching', 'materials', 'to', 'help', 'students', 'better', 'understand', 'learning', 'concepts', 'helped', 'students', 'take', 'advantage', 'of', 'other', 'available', 'subject', 'matter', 'and', 'study', 'resources', 'classroom', 'restocking', 'support', 'and', 'management', 'of', 'operations', 'arranged', 'and', 'led', 'activities', 'for', 'students', 'including', 'small', 'group', 'and', 'individualized', 'instructions', 'assisted', 'teachers', 'with', 'lesson', 'preparation', 'curriculum', 'implementation', 'and', 'testing', 'assistant', 'manager', 'intern', 'city', 'state', 'company', 'name', 'may', '2006', 'to', 'sep', '2006', 'spearheaded', 'training', 'initiatives', 'to', 'improve', 'employee', 'performance', 'and', 'bottomline', 'business', 'results', 'generated', 'reports', 'to', 'assess', 'performance', 'and', 'make', 'adjustments', 'increased', 'customer', 'base', 'and', 'market', 'share', 'by', 'promoting', 'product', 'through', 'diverse', 'channels', 'optimized', 'productivity', 'streamlined', 'program', 'efficiency', 'and', 'boosted', 'profitability', 'supervised', 'and', 'trained', 'customer', 'service', 'team', 'members', 'to', 'provide', 'exceptional', 'service', 'driving', 'retention', 'and', 'satisfaction', 'remained', 'calm', 'and', 'professional', 'in', 'stressful', 'circumstances', 'and', 'when', 'dealing', 'with', 'unhappy', 'customers', 'effectively', 'diffusing', 'situations', 'addressed', 'internal', 'and', 'customerrelated', 'issues', 'each', 'day', 'and', 'affected', 'strategic', 'resolutions', 'junior', 'editor', 'city', 'state', 'company', 'name', 'sep', '2004', 'to', 'sep', '2006', 'determined', 'appropriate', 'page', 'budgets', 'and', 'layouts', 'to', 'guide', 'word', 'count', 'parameters', 'optimize', 'use', 'of', 'images', 'and', 'graphics', 'as', 'well', 'as', 'maximize', 'impact', 'within', 'allotted', 'space', 'evaluated', 'reporter', 'stories', 'shaped', 'content', 'and', 'helped', 'improve', 'overall', 'work', 'quality', 'through', 'careful', 'review', 'detailed', 'editing', 'and', 'constructive', 'feedback', 'developed', 'and', 'deepened', 'positive', 'relationships', 'with', 'writing', 'design', 'and', 'production', 'team', 'members', 'to', 'improve', 'communication', 'and', 'collaboration', 'handed', 'out', 'story', 'assignments', 'directed', 'content', 'meetings', 'and', 'evaluated', 'submitted', 'pieces', 'to', 'manage', 'overall', 'tone', 'and', 'execution', 'of', 'work', 'decided', 'readiness', 'of', 'articles', 'for', 'publication', 'and', 'approved', 'final', 'versions', 'edited', 'rewrote', 'and', 'prepared', 'numerous', 'pieces', 'per', 'week', 'by', 'adjusting', 'reading', 'level', 'to', 'make', 'understanding', 'articles', 'easier', 'and', 'more', 'interesting', 'oversaw', 'layout', 'design', 'and', 'worked', 'with', 'production', 'team', 'members', 'to', 'complete', 'fresh', 'monthly', 'publications', 'education', 'and', 'training', 'mba', 'marketing', 'iglobal', 'university', 'jun', '2015', 'city', 'state', 'major', 'in', 'marketing', 'completed', 'coursework', 'in', 'bba', 'business', 'administration', 'golden', 'gate', 'university', 'jun', '2011', 'city', 'state', 'international', 'student', 'scholarship', 'recipient', 'minor', 'in', 'international', 'business', 'associate', 'of', 'arts', 'suffolk', 'university', 'jun', '2007', 'city', 'associate', 'in', 'international', 'business', 'and', 'business', 'administration']\n",
      "Extracted skills: []\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(\"Resume:\", resume_sample_df['Resume_str'].iloc[i])\n",
    "    print(\"Tokens:\", resume_sample_df['processed_resume'].iloc[i]['original'])\n",
    "    print(\"Extracted skills:\", resume_sample_df['cv_skills'].iloc[i])\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2a5f6908-c4f9-4afb-8209-c78cb28c0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(text_data):\n",
    "    if pd.isna(text_data) or not isinstance(text_data, dict):\n",
    "        return []\n",
    "    original_terms = [term.lower() for term in text_data['original']]\n",
    "    return [skill for skill in SKILLS if skill in original_terms]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c84ad144-1904-4b63-b688-920b71830775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted skills: ['python', 'aws', 'docker']\n"
     ]
    }
   ],
   "source": [
    "skills_employe = extract_skills(text_data)\n",
    "\n",
    "\n",
    "print(\"Extracted skills:\", skills_employe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4caf37ed-2d7f-452d-9f77-2a562feb34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills(text_data):\n",
    "    if pd.isna(text_data) or not isinstance(text_data, dict):\n",
    "        return []\n",
    "    original_terms = set([term.lower() for term in text_data['original']])\n",
    "    return [skill for skill in SKILLS if skill in original_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "144aa1db-5a4c-4a17-8647-29a382603c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted skills: ['python', 'aws', 'docker']\n"
     ]
    }
   ],
   "source": [
    "skills_employe = extract_skills(text_data)\n",
    "\n",
    "\n",
    "print(\"Extracted skills:\", skills_employe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497f752-5576-424c-bf19-3f55cba27734",
   "metadata": {},
   "source": [
    "# Use NLTK for basic tokenization and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ccf80448-7190-4212-bf4d-650afca29061",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills found: ['aws', 'python', 'docker']\n",
      "Domains found: ['healthcare', 'finance', 'tech']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Gouthum/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Gouthum/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Gouthum/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Download required nltk data once\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def normalize_and_lemmatize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmas\n",
    "\n",
    "text = \"Looking for a python developer with experience in AWS and docker, wanted 5+years expereince in healthcare', 'finance', 'tech'.\"\n",
    "lemmas = normalize_and_lemmatize(text)\n",
    "\n",
    "SKILLS = ['javascript', 'node.js', 'aws', 'kubernetes', 'golang', 'ruby', 'python', 'sql', 'java', \n",
    "          'docker', 'html', 'management', 'engineering', 'marketing', 'design', 'sales', 'software', \n",
    "          'development', 'communication', 'leadership', 'installation', 'technical', 'automation', 'power systems']\n",
    "\n",
    "DOMAINS = ['healthcare', 'finance', 'tech', 'education', 'manufacturing', 'retail', 'sales', \n",
    "           'construction', 'hospitality', 'engineering', 'legal', 'marketing', 'government']\n",
    "\n",
    "matched_skills = [skill for skill in SKILLS if skill in lemmas]\n",
    "matched_domains = [domain for domain in DOMAINS if domain in lemmas]\n",
    "\n",
    "print(\"Skills found:\", matched_skills)\n",
    "print(\"Domains found:\", matched_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20880a-4874-4709-89c7-e7511339018b",
   "metadata": {},
   "source": [
    "# simple Python text processing (no spaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36793625-c4a3-4642-afb1-baa80e7d8963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills found: ['aws', 'python', 'docker']\n",
      "Domains found: ['healthcare', 'finance']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample text (e.g., job description or resume text)\n",
    "text = \"Looking for a python developer with experience in AWS and docker healthcare in finance.\"\n",
    "\n",
    "# Normalize text: lowercase and remove punctuation\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # remove punctuation\n",
    "    return text\n",
    "\n",
    "normalized_text = normalize_text(text)\n",
    "\n",
    "# Define keywords\n",
    "SKILLS = ['javascript', 'node.js', 'aws', 'kubernetes', 'go lang', 'ruby', 'python', 'sql', 'java', \n",
    "          'docker', 'html', 'management', 'engineering', 'marketing', 'design', 'sales', 'software', \n",
    "          'development', 'communication', 'leadership', 'installation', 'technical', 'automation', 'power systems']\n",
    "\n",
    "DOMAINS = ['healthcare', 'finance', 'tech', 'education', 'manufacturing', 'retail', 'sales', \n",
    "           'construction', 'hospitality', 'engineering', 'legal', 'marketing', 'government']\n",
    "\n",
    "# Extract matched keywords from text\n",
    "matched_skills = [skill for skill in SKILLS if skill in normalized_text]\n",
    "matched_domains = [domain for domain in DOMAINS if domain in normalized_text]\n",
    "\n",
    "print(\"Skills found:\", matched_skills)\n",
    "print(\"Domains found:\", matched_domains)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5e922-1abe-4801-bdde-8317de3425c3",
   "metadata": {},
   "source": [
    "#### Combine data into a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "645a284d-3550-4cbe-b212-e7b31cdf93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_data = postings_sample_df[['job_id', 'title', 'processed_desc', 'job_skills', 'job_domain']].copy()\n",
    "resume_data = resume_sample_df[['ID', 'Resume_str', 'processed_resume', 'cv_skills', 'cv_domain']].copy()\n",
    "combined_data = pd.concat([job_data.assign(type='job'), resume_data.assign(type='resume')], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a0632a2-3462-469d-93bc-2eeebdf0626f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>processed_desc</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73989</th>\n",
       "      <td>3902944011</td>\n",
       "      <td>Senior Automation Engineer - Power Systems</td>\n",
       "      <td>{'original': ['the', 'senior', 'automation', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59308</th>\n",
       "      <td>3901960222</td>\n",
       "      <td>DISH Installation Technician - Field</td>\n",
       "      <td>{'original': ['company', 'summary', 'dish', 'a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44663</th>\n",
       "      <td>3900944095</td>\n",
       "      <td>Order Builder</td>\n",
       "      <td>{'original': ['division', 'north', 'alabama', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tech, education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81954</th>\n",
       "      <td>3903878594</td>\n",
       "      <td>Mountain Multimedia Journalist, KMGH</td>\n",
       "      <td>{'original': ['kmgh', 'the', 'ew', 'scripps', ...</td>\n",
       "      <td>[aws]</td>\n",
       "      <td>[business, tech]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113151</th>\n",
       "      <td>3905670593</td>\n",
       "      <td>Licensed Practical Nurse (LPN)</td>\n",
       "      <td>{'original': ['come', 'for', 'the', 'flexibili...</td>\n",
       "      <td>[aws]</td>\n",
       "      <td>[tech]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74903</th>\n",
       "      <td>3903442844</td>\n",
       "      <td>R &amp; D Chemist - Coatings</td>\n",
       "      <td>{'original': ['rd', 'staff', 'chemist', 'coati...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tech]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11601</th>\n",
       "      <td>3887496577</td>\n",
       "      <td>Senior Accounting Manager</td>\n",
       "      <td>{'original': ['about', 'the', 'companyour', 'c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tech, finance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53215</th>\n",
       "      <td>3901638416</td>\n",
       "      <td>Med-Surg Registered Nurse</td>\n",
       "      <td>{'original': ['medpro', 'healthcare', 'staffin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[healthcare]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50579</th>\n",
       "      <td>3901374545</td>\n",
       "      <td>Intern - Chemist/Biologist</td>\n",
       "      <td>{'original': ['overview', 'systems', 'planning...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66711</th>\n",
       "      <td>3902748706</td>\n",
       "      <td>Financial Specialist</td>\n",
       "      <td>{'original': ['overview', 'financial', 'specia...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            job_id                                       title  \\\n",
       "73989   3902944011  Senior Automation Engineer - Power Systems   \n",
       "59308   3901960222        DISH Installation Technician - Field   \n",
       "44663   3900944095                               Order Builder   \n",
       "81954   3903878594        Mountain Multimedia Journalist, KMGH   \n",
       "113151  3905670593              Licensed Practical Nurse (LPN)   \n",
       "...            ...                                         ...   \n",
       "74903   3903442844                    R & D Chemist - Coatings   \n",
       "11601   3887496577                   Senior Accounting Manager   \n",
       "53215   3901638416                   Med-Surg Registered Nurse   \n",
       "50579   3901374545                  Intern - Chemist/Biologist   \n",
       "66711   3902748706                        Financial Specialist   \n",
       "\n",
       "                                           processed_desc job_skills  \\\n",
       "73989   {'original': ['the', 'senior', 'automation', '...         []   \n",
       "59308   {'original': ['company', 'summary', 'dish', 'a...         []   \n",
       "44663   {'original': ['division', 'north', 'alabama', ...         []   \n",
       "81954   {'original': ['kmgh', 'the', 'ew', 'scripps', ...      [aws]   \n",
       "113151  {'original': ['come', 'for', 'the', 'flexibili...      [aws]   \n",
       "...                                                   ...        ...   \n",
       "74903   {'original': ['rd', 'staff', 'chemist', 'coati...         []   \n",
       "11601   {'original': ['about', 'the', 'companyour', 'c...         []   \n",
       "53215   {'original': ['medpro', 'healthcare', 'staffin...         []   \n",
       "50579   {'original': ['overview', 'systems', 'planning...         []   \n",
       "66711   {'original': ['overview', 'financial', 'specia...         []   \n",
       "\n",
       "               job_domain  \n",
       "73989    [business, tech]  \n",
       "59308    [business, tech]  \n",
       "44663   [tech, education]  \n",
       "81954    [business, tech]  \n",
       "113151             [tech]  \n",
       "...                   ...  \n",
       "74903              [tech]  \n",
       "11601     [tech, finance]  \n",
       "53215        [healthcare]  \n",
       "50579    [business, tech]  \n",
       "66711                  []  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "37cf5d9e-c423-4bd2-9164-23315e8a8f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>processed_resume</th>\n",
       "      <th>cv_skills</th>\n",
       "      <th>cv_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>99244405</td>\n",
       "      <td>Kpandipou    Koffi         Summary ...</td>\n",
       "      <td>{'original': ['kpandipou', 'koffi', 'summary',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>17562754</td>\n",
       "      <td>DIRECTOR OF DIGITAL TRANSFORMATION   ...</td>\n",
       "      <td>{'original': ['director', 'of', 'digital', 'tr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech, education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>30311725</td>\n",
       "      <td>SENIOR PROJECT MANAGER       Professi...</td>\n",
       "      <td>{'original': ['senior', 'project', 'manager', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, education, finance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>19007667</td>\n",
       "      <td>CHEF       Summary     Experienced ca...</td>\n",
       "      <td>{'original': ['chef', 'summary', 'experienced'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>11065180</td>\n",
       "      <td>OPERATIONS MANAGER       Summary    E...</td>\n",
       "      <td>{'original': ['operations', 'manager', 'summar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech, education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>23918545</td>\n",
       "      <td>CLAIMS SERVICE SPECIALIST         Pro...</td>\n",
       "      <td>{'original': ['claims', 'service', 'specialist...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[healthcare, business, education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>91467795</td>\n",
       "      <td>BUSINESS DEVELOPMENT CONSULTANT      ...</td>\n",
       "      <td>{'original': ['business', 'development', 'cons...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech, education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>25862026</td>\n",
       "      <td>SENIOR ACCOUNTANT       Summary    8+...</td>\n",
       "      <td>{'original': ['senior', 'accountant', 'summary...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>27372171</td>\n",
       "      <td>INFORMATION TECHNOLOGY SPECIALIST/SYS...</td>\n",
       "      <td>{'original': ['information', 'technology', 'sp...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech, education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>75744306</td>\n",
       "      <td>CUSTOMER SERVICE REPRESENTATIVE      ...</td>\n",
       "      <td>{'original': ['customer', 'service', 'represen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[healthcare, tech, education]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                         Resume_str  \\\n",
       "420   99244405             Kpandipou    Koffi         Summary ...   \n",
       "1309  17562754           DIRECTOR OF DIGITAL TRANSFORMATION   ...   \n",
       "2023  30311725           SENIOR PROJECT MANAGER       Professi...   \n",
       "1360  19007667           CHEF       Summary     Experienced ca...   \n",
       "2186  11065180           OPERATIONS MANAGER       Summary    E...   \n",
       "...        ...                                                ...   \n",
       "750   23918545           CLAIMS SERVICE SPECIALIST         Pro...   \n",
       "657   91467795           BUSINESS DEVELOPMENT CONSULTANT      ...   \n",
       "1866  25862026           SENIOR ACCOUNTANT       Summary    8+...   \n",
       "234   27372171           INFORMATION TECHNOLOGY SPECIALIST/SYS...   \n",
       "732   75744306           CUSTOMER SERVICE REPRESENTATIVE      ...   \n",
       "\n",
       "                                       processed_resume cv_skills  \\\n",
       "420   {'original': ['kpandipou', 'koffi', 'summary',...        []   \n",
       "1309  {'original': ['director', 'of', 'digital', 'tr...        []   \n",
       "2023  {'original': ['senior', 'project', 'manager', ...        []   \n",
       "1360  {'original': ['chef', 'summary', 'experienced'...        []   \n",
       "2186  {'original': ['operations', 'manager', 'summar...        []   \n",
       "...                                                 ...       ...   \n",
       "750   {'original': ['claims', 'service', 'specialist...        []   \n",
       "657   {'original': ['business', 'development', 'cons...        []   \n",
       "1866  {'original': ['senior', 'accountant', 'summary...        []   \n",
       "234   {'original': ['information', 'technology', 'sp...        []   \n",
       "732   {'original': ['customer', 'service', 'represen...        []   \n",
       "\n",
       "                              cv_domain  \n",
       "420               [business, education]  \n",
       "1309        [business, tech, education]  \n",
       "2023     [business, education, finance]  \n",
       "1360                                 []  \n",
       "2186        [business, tech, education]  \n",
       "...                                 ...  \n",
       "750   [healthcare, business, education]  \n",
       "657         [business, tech, education]  \n",
       "1866                        [education]  \n",
       "234         [business, tech, education]  \n",
       "732       [healthcare, tech, education]  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d6465ec4-c3e8-47db-ba88-cb9a2d7a4a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>processed_desc</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_domain</th>\n",
       "      <th>type</th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>processed_resume</th>\n",
       "      <th>cv_skills</th>\n",
       "      <th>cv_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.902944e+09</td>\n",
       "      <td>Senior Automation Engineer - Power Systems</td>\n",
       "      <td>{'original': ['the', 'senior', 'automation', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech]</td>\n",
       "      <td>job</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.901960e+09</td>\n",
       "      <td>DISH Installation Technician - Field</td>\n",
       "      <td>{'original': ['company', 'summary', 'dish', 'a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech]</td>\n",
       "      <td>job</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.900944e+09</td>\n",
       "      <td>Order Builder</td>\n",
       "      <td>{'original': ['division', 'north', 'alabama', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tech, education]</td>\n",
       "      <td>job</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.903879e+09</td>\n",
       "      <td>Mountain Multimedia Journalist, KMGH</td>\n",
       "      <td>{'original': ['kmgh', 'the', 'ew', 'scripps', ...</td>\n",
       "      <td>[aws]</td>\n",
       "      <td>[business, tech]</td>\n",
       "      <td>job</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.905671e+09</td>\n",
       "      <td>Licensed Practical Nurse (LPN)</td>\n",
       "      <td>{'original': ['come', 'for', 'the', 'flexibili...</td>\n",
       "      <td>[aws]</td>\n",
       "      <td>[tech]</td>\n",
       "      <td>job</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resume</td>\n",
       "      <td>23918545.0</td>\n",
       "      <td>CLAIMS SERVICE SPECIALIST         Pro...</td>\n",
       "      <td>{'original': ['claims', 'service', 'specialist...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[healthcare, business, education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resume</td>\n",
       "      <td>91467795.0</td>\n",
       "      <td>BUSINESS DEVELOPMENT CONSULTANT      ...</td>\n",
       "      <td>{'original': ['business', 'development', 'cons...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech, education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resume</td>\n",
       "      <td>25862026.0</td>\n",
       "      <td>SENIOR ACCOUNTANT       Summary    8+...</td>\n",
       "      <td>{'original': ['senior', 'accountant', 'summary...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resume</td>\n",
       "      <td>27372171.0</td>\n",
       "      <td>INFORMATION TECHNOLOGY SPECIALIST/SYS...</td>\n",
       "      <td>{'original': ['information', 'technology', 'sp...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[business, tech, education]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resume</td>\n",
       "      <td>75744306.0</td>\n",
       "      <td>CUSTOMER SERVICE REPRESENTATIVE      ...</td>\n",
       "      <td>{'original': ['customer', 'service', 'represen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[healthcare, tech, education]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            job_id                                       title  \\\n",
       "0     3.902944e+09  Senior Automation Engineer - Power Systems   \n",
       "1     3.901960e+09        DISH Installation Technician - Field   \n",
       "2     3.900944e+09                               Order Builder   \n",
       "3     3.903879e+09        Mountain Multimedia Journalist, KMGH   \n",
       "4     3.905671e+09              Licensed Practical Nurse (LPN)   \n",
       "...            ...                                         ...   \n",
       "3995           NaN                                         NaN   \n",
       "3996           NaN                                         NaN   \n",
       "3997           NaN                                         NaN   \n",
       "3998           NaN                                         NaN   \n",
       "3999           NaN                                         NaN   \n",
       "\n",
       "                                         processed_desc job_skills  \\\n",
       "0     {'original': ['the', 'senior', 'automation', '...         []   \n",
       "1     {'original': ['company', 'summary', 'dish', 'a...         []   \n",
       "2     {'original': ['division', 'north', 'alabama', ...         []   \n",
       "3     {'original': ['kmgh', 'the', 'ew', 'scripps', ...      [aws]   \n",
       "4     {'original': ['come', 'for', 'the', 'flexibili...      [aws]   \n",
       "...                                                 ...        ...   \n",
       "3995                                                NaN        NaN   \n",
       "3996                                                NaN        NaN   \n",
       "3997                                                NaN        NaN   \n",
       "3998                                                NaN        NaN   \n",
       "3999                                                NaN        NaN   \n",
       "\n",
       "             job_domain    type          ID  \\\n",
       "0      [business, tech]     job         NaN   \n",
       "1      [business, tech]     job         NaN   \n",
       "2     [tech, education]     job         NaN   \n",
       "3      [business, tech]     job         NaN   \n",
       "4                [tech]     job         NaN   \n",
       "...                 ...     ...         ...   \n",
       "3995                NaN  resume  23918545.0   \n",
       "3996                NaN  resume  91467795.0   \n",
       "3997                NaN  resume  25862026.0   \n",
       "3998                NaN  resume  27372171.0   \n",
       "3999                NaN  resume  75744306.0   \n",
       "\n",
       "                                             Resume_str  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3                                                   NaN   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "3995           CLAIMS SERVICE SPECIALIST         Pro...   \n",
       "3996           BUSINESS DEVELOPMENT CONSULTANT      ...   \n",
       "3997           SENIOR ACCOUNTANT       Summary    8+...   \n",
       "3998           INFORMATION TECHNOLOGY SPECIALIST/SYS...   \n",
       "3999           CUSTOMER SERVICE REPRESENTATIVE      ...   \n",
       "\n",
       "                                       processed_resume cv_skills  \\\n",
       "0                                                   NaN       NaN   \n",
       "1                                                   NaN       NaN   \n",
       "2                                                   NaN       NaN   \n",
       "3                                                   NaN       NaN   \n",
       "4                                                   NaN       NaN   \n",
       "...                                                 ...       ...   \n",
       "3995  {'original': ['claims', 'service', 'specialist...        []   \n",
       "3996  {'original': ['business', 'development', 'cons...        []   \n",
       "3997  {'original': ['senior', 'accountant', 'summary...        []   \n",
       "3998  {'original': ['information', 'technology', 'sp...        []   \n",
       "3999  {'original': ['customer', 'service', 'represen...        []   \n",
       "\n",
       "                              cv_domain  \n",
       "0                                   NaN  \n",
       "1                                   NaN  \n",
       "2                                   NaN  \n",
       "3                                   NaN  \n",
       "4                                   NaN  \n",
       "...                                 ...  \n",
       "3995  [healthcare, business, education]  \n",
       "3996        [business, tech, education]  \n",
       "3997                        [education]  \n",
       "3998        [business, tech, education]  \n",
       "3999      [healthcare, tech, education]  \n",
       "\n",
       "[4000 rows x 11 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "00641735-e859-4b18-9d69-e03bade6143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type        job_skills                       job_domain\n",
      "0   job                []                 [business, tech]\n",
      "1   job                []                 [business, tech]\n",
      "2   job                []                [tech, education]\n",
      "3   job             [aws]                 [business, tech]\n",
      "4   job             [aws]                           [tech]\n",
      "5   job                []                       [business]\n",
      "6   job             [aws]                [tech, education]\n",
      "7   job                []                           [tech]\n",
      "8   job  [aws, java, sql]                           [tech]\n",
      "9   job                []                               []\n",
      "10  job                []                           [tech]\n",
      "11  job                []                 [business, tech]\n",
      "12  job                []  [healthcare, business, finance]\n",
      "13  job                []    [healthcare, tech, education]\n",
      "14  job                []                               []\n"
     ]
    }
   ],
   "source": [
    "print(combined_data[['type', 'job_skills', 'job_domain']].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e332d-21be-40f9-aa3d-c44091c39d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b9646b4-2347-465f-b8af-b4d49ee009b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (1.24.3)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (3.14.0)\n",
      "Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-2.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'C:\\Users\\Gouthum\\.conda\\envs\\myenv\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Gouthum\\.conda\\envs\\myenv\\Lib\\site-packages\\numpy\\~-ibs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Gouthum\\AppData\\Local\\Temp\\pip-uninstall-q3alppgf'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 4.0.0 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.14.1 which is incompatible.\n",
      "streamlit 1.45.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.14.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "321ca81a-86bf-4b92-b33e-256794d395fb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
      "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"C:\\Users\\Gouthum\\AppData\\Roaming\\Python\\Python312\\site-packages\\thinc\\compat.py\", line 99, in <module>\n",
      "    import h5py\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py\", line 45, in <module>\n",
      "    from ._conv import register_converters as _register_converters, \\\n",
      "  File \"h5py\\\\_conv.pyx\", line 1, in init h5py._conv\n",
      "  File \"h5py\\\\h5r.pyx\", line 1, in init h5py.h5r\n",
      "  File \"h5py\\\\h5p.pyx\", line 1, in init h5py.h5p\n",
      "ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d65ab87c-52c4-4b29-b3c7-5be44507ea8f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load spaCy model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\spacy\\__init__.py:52\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     29\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     36\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\spacy\\util.py:484\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141fc9f1-ea59-404b-8f45-19083c1581ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0684cf02-a3d0-4e2a-8bfc-5165923a1d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers==4.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (4.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: transformers==4.51.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: huggingface-hub==0.31.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (0.31.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==4.1.0) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==4.1.0) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==4.1.0) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==4.1.0) (1.15.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==4.1.0) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sentence-transformers==4.1.0) (4.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.51.3) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.51.3) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.51.3) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.51.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.51.3) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.51.3) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.51.3) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from transformers==4.51.3) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from huggingface-hub==0.31.1) (2025.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==4.1.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==4.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers==4.1.0) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers==4.1.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from tqdm->sentence-transformers==4.1.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers==4.1.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers==4.51.3) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers==4.51.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers==4.51.3) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from requests->transformers==4.51.3) (2025.6.15)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers==4.1.0) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages (from scikit-learn->sentence-transformers==4.1.0) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers==4.1.0 transformers==4.51.3 huggingface-hub==0.31.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "145b3a38-c078-4086-bd57-c6c5b598fd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.51.3\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: sentence-transformers\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d44e478f-fbee-4d9d-b9fe-af142e457333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sentence-transformersNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 4.1.0\n",
      "Summary: Embeddings, Retrieval, and Reranking\n",
      "Home-page: https://www.SBERT.net\n",
      "Author: \n",
      "Author-email: Nils Reimers <info@nils-reimers.de>, Tom Aarsen <tom.aarsen@huggingface.co>\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\gouthum\\.conda\\envs\\myenv\\lib\\site-packages\n",
      "Requires: huggingface-hub, Pillow, scikit-learn, scipy, torch, tqdm, transformers, typing_extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "pip show sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9a550-13f5-482a-ae2c-fe6dc0595742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
